{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have configured Azure AI services and set the appropriate configuration parameters. You can find the setup instructions [here](README.md).\n",
    "\n",
    "## 📋 Table of Contents\n",
    "\n",
    "This notebook guides you through the following sections:\n",
    "\n",
    "1. [**Speech to Text from Local Files**](#speech-to-text-from-local-files): This section covers how to convert speech to text from various audio file formats stored locally on your machine.\n",
    "\n",
    "2. [**Speech to Text from Blob Storage**](#blob-storage): Learn how to convert speech to text from audio files stored in Azure Blob Storage.\n",
    "\n",
    "3. [**Speech to Text from Streams**](#streams): This section demonstrates how to convert speech to text from audio streams, using push streams for real-time processing.\n",
    "\n",
    "For more details, refer to the following resources:\n",
    "- [Quickstart: Azure Cognitive Services Speech SDK](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master)\n",
    "\n",
    "### 🛠️ Notebook Setup (Optional)\n",
    "\n",
    "#### Setting Up Conda Environment and Configuring VSCode for Jupyter Notebooks\n",
    "\n",
    "Follow these steps to create a Conda environment and set up your VSCode for running Jupyter Notebooks:\n",
    "\n",
    "##### Create Conda Environment from the Repository\n",
    "\n",
    "> Instructions for Windows users: \n",
    "\n",
    "1. **Create the Conda Environment**:\n",
    "   - In your terminal or command line, navigate to the repository directory.\n",
    "   - Execute the following command to create the Conda environment using the `environment.yml` file:\n",
    "     ```bash\n",
    "     conda env create -f environment.yml\n",
    "     ```\n",
    "   - This command creates a Conda environment as defined in `environment.yml`.\n",
    "\n",
    "2. **Activating the Environment**:\n",
    "   - After creation, activate the new Conda environment by using:\n",
    "     ```bash\n",
    "     conda activate speech-ai-azure-services\n",
    "     ```\n",
    "\n",
    "> Instructions for Linux users (or Windows users with WSL or other linux setup): \n",
    "\n",
    "1. **Use `make` to Create the Conda Environment**:\n",
    "   - In your terminal or command line, navigate to the repository directory and look at the Makefile.\n",
    "   - Execute the `make` command specified below to create the Conda environment using the `environment.yml` file:\n",
    "     ```bash\n",
    "     make create_conda_env\n",
    "     ```\n",
    "\n",
    "2. **Activating the Environment**:\n",
    "   - After creation, activate the new Conda environment by using:\n",
    "     ```bash\n",
    "     conda activate speech-ai-azure-services\n",
    "     ```\n",
    "\n",
    "##### Configure VSCode for Jupyter Notebooks\n",
    "\n",
    "1. **Install Required Extensions**:\n",
    "   - Download and install the `Python` and `Jupyter` extensions for VSCode. These extensions provide support for running and editing Jupyter Notebooks within VSCode.\n",
    "\n",
    "2. **Attach Kernel to VSCode**:\n",
    "   - After creating the Conda environment, it should be available in the kernel selection dropdown. This dropdown is located in the top-right corner of the VSCode interface.\n",
    "   - Select your newly created environment (`speech-ai-azure-services`) from the dropdown. This sets it as the kernel for running your Jupyter Notebooks.\n",
    "\n",
    "3. **Run the Notebook**:\n",
    "   - Once the kernel is attached, you can run the notebook by clicking on the \"Run All\" button in the top menu, or by running each cell individually.\n",
    "\n",
    "By following these steps, you'll establish a dedicated Conda environment for your project and configure VSCode to run Jupyter Notebooks efficiently. This environment will include all the necessary dependencies specified in your `environment.yml` file. If you wish to add more packages or change versions, please use `pip install` in a notebook cell or in the terminal after activating the environment, and then restart the kernel. The changes should be automatically applied after the session restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "target_directory = (\n",
    "    r\"C:\\Users\\pablosal\\Desktop\\sharepoint-indexing-azure-cognitive-search\"\n",
    ")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text from Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SpeechTranscriber class from the speech_to_text module in the src.speech package\n",
    "from src.speech.speech_to_text import SpeechTranscriber\n",
    "\n",
    "# Create an instance of the SpeechTranscriber class\n",
    "transcriber_client = SpeechTranscriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_PCM_STEREO = \"C://Users//pablosal//Desktop//gbbai-azure-ai-speech-services//utils//audio_data//d6a35a5e-be01-40cd-b9ef-d61fcda699fa.pcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:28:29,278 - micro - MainProcess - INFO     SESSION STARTED: SessionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca) (speech_to_text.py:<lambda>:129)\n",
      "2023-12-26 17:28:30,464 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=578782ea3b8e4e7a86b3843cb5a1855c, text=\"what is the date\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:31,050 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=063c72a5c1cf423a98f23155fc33ba40, text=\"may 15th 1980\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:31,903 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=162b2d82632a486084d7c539bac8f8b6, text=\"thursday\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:31,979 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=2ce0a94021b141fcbbbd58ceeffbcdbb, text=\"thursday may\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:32,185 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=29ac296ee7924c188b2227467ba1e34c, text=\"thursday may 15th\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:32,603 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=d458348c37cd4b37952540d991d7450c, text=\"thursday may 15th ninet\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:32,689 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=8f5b27ab0b6649308c468307f1b45430, text=\"thursday may 15th 19\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:32,776 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=39bf59ec603f4bff841142804620e4e9, text=\"thursday may 15th 1900\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:32,885 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=41931c017b5f4bb2a1eb21aa266b7887, text=\"thursday may 15th 19180\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:33,802 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=e2445b061f4c46579ea7afcbc34c97c8, text=\"what is\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:33,913 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=87ab69fbada04fa192f38de5de8ecd51, text=\"what is the date\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:37,186 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=5988218afdb4460c930d7d01b7d506d5, text=\"saturday\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:37,388 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=60324561ace04aaabf0cf543449262f9, text=\"saturday july\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:37,792 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=b20a3e4aab39499092853c5b10aaf227, text=\"saturday july 6\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:37,999 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=329902a939e94c2a9ad5cbf1ada372c4, text=\"saturday july 6th 2:00\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:38,197 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=bbf68e009ea9463683e8f21bf1aca7de, text=\"saturday july 6th 2000\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:38,398 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=2698795a9991466b9dcab0b63e33123b, text=\"saturday july 6th 2020\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:125)\n",
      "2023-12-26 17:28:38,681 - micro - MainProcess - INFO     CANCELED SpeechRecognitionCanceledEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=d0d5974ca02944108d84be729481d2c4, text=\"\", reason=ResultReason.Canceled)) (speech_to_text.py:<lambda>:134)\n",
      "2023-12-26 17:28:38,684 - micro - MainProcess - INFO     CLOSING on SpeechRecognitionCanceledEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca, result=SpeechRecognitionResult(result_id=d0d5974ca02944108d84be729481d2c4, text=\"\", reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:120)\n",
      "2023-12-26 17:28:38,687 - micro - MainProcess - INFO     SESSION STOPPED SessionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca) (speech_to_text.py:<lambda>:132)\n",
      "2023-12-26 17:28:38,691 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=78cf3c53053c40b6ba579aea9b57b8ca) (speech_to_text.py:stop_cb:120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? Saturday, July 6th, 2024.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the transcribe_speech_from_file_continuous method of the transcriber_client object\n",
    "# Pass the AUDIO_FILE_PCM_STEREO constant as the file_name argument\n",
    "# Pass the following arguments OPTIONAL:\n",
    "# language (str): The language to use for speech recognition. This parameter is optional and defaults to None.\n",
    "# source_language_config (SourceLanguageConfig): The source language configuration. This parameter is optional and defaults to None.\n",
    "# auto_detect_source_language_config (AutoDetectSourceLanguageConfig): The auto detect source language configuration. This parameter is optional and defaults to None.\n",
    "\n",
    "transcriber_client.transcribe_speech_from_file_continuous(file_name=AUDIO_FILE_PCM_STEREO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text from Blob Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_PCM_STEREO_BLOB = \"https://testeastusdev001.blob.core.windows.net/speechapp/d6a35a5e-be01-40cd-b9ef-d61fcda699fa.pcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:33:44,365 - micro - MainProcess - INFO     SESSION STARTED: SessionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b) (speech_to_text.py:<lambda>:186)\n",
      "2023-12-26 17:33:45,621 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=ddd3e26e327b42278483f93b8bcf1ba1, text=\"what is the date\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:46,151 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=35725cb234484242b069438844aeec54, text=\"may 15th 1980\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:46,787 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=6a320224089f4b5ca8b45da66895ce24, text=\"thursday\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:47,082 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=bb61aa704c0e4d55bf1e6d00aaa37ca5, text=\"thursday may\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:47,298 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=8c5ffcd508fc4b6493e5401b52fc3ebd, text=\"thursday may 15th\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:47,682 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=a816900e1f9d45f8817657c696be5f89, text=\"thursday may 15th 19\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:47,791 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=a6aecdcc16484a7abc312e19765f12fb, text=\"thursday may 15th 1900\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:47,993 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=fe157751794748b89a2ff853168e2e1f, text=\"thursday may 15th 19180\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:48,874 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=4e449b9017834102a8eec3dfde3a6141, text=\"what is\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:48,967 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=767aeaf6632041f480e8557d0d8550b9, text=\"what is the date\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:52,296 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=3a23cf90767f453ba3a14def2fa343a0, text=\"saturday\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:52,500 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=12716d3978604bdfa51b8e41a85c6e71, text=\"saturday july\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:52,889 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=63edb0c54e86410f94a332c7ccc24df0, text=\"saturday july 6th\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:53,090 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=c7459646f26244d88a5c78781f3ce8b0, text=\"saturday july 6th 2:00\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:53,321 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=9af4b312d981442abde3ccdb6e8d1970, text=\"saturday july 6th 2000\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:53,494 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=56f37883b27f4758897537717402b8a9, text=\"saturday july 6th 2020\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:182)\n",
      "2023-12-26 17:33:53,870 - micro - MainProcess - INFO     CANCELED SpeechRecognitionCanceledEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=9f06d7b85b974369a50a3e7cee6ea109, text=\"\", reason=ResultReason.Canceled)) (speech_to_text.py:<lambda>:191)\n",
      "2023-12-26 17:33:53,875 - micro - MainProcess - INFO     CLOSING on SpeechRecognitionCanceledEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b, result=SpeechRecognitionResult(result_id=9f06d7b85b974369a50a3e7cee6ea109, text=\"\", reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:177)\n",
      "2023-12-26 17:33:53,877 - micro - MainProcess - INFO     SESSION STOPPED SessionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b) (speech_to_text.py:<lambda>:189)\n",
      "2023-12-26 17:33:53,883 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=fb2a4a5af38b4cd181900a054b8e502b) (speech_to_text.py:stop_cb:177)\n",
      "2023-12-26 17:33:53,885 - micro - MainProcess - WARNING  Error deleting temporary file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\Temp\\\\tmp_unteqcb' (speech_to_text.py:transcribe_speech_from_blob_continuous:203)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? Saturday, July 6th, 2024.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber_client.transcribe_speech_from_blob_continuous(blob_url=AUDIO_FILE_PCM_STEREO_BLOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text from streams (preview):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.speech.utils_audio import check_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_PCM_MONO = \"C://Users//pablosal//Desktop//gbbai-azure-ai-speech-services//utils//audio_data//aboutSpeechSdk.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:39:28,901 - micro - MainProcess - INFO     PCM Format (int-16): True (utils_audio.py:check_audio_file:38)\n",
      "2023-12-26 17:39:28,902 - micro - MainProcess - INFO     One Channel (Mono): True (utils_audio.py:check_audio_file:42)\n",
      "2023-12-26 17:39:28,903 - micro - MainProcess - INFO     Valid Sample Rate (8000 or 16000 Hz): True (utils_audio.py:check_audio_file:46)\n",
      "2023-12-26 17:39:28,904 - micro - MainProcess - INFO     Bytes Per Second (16000 or 32000): 32000 (utils_audio.py:check_audio_file:50)\n",
      "2023-12-26 17:39:28,904 - micro - MainProcess - INFO     Two-block Aligned: True (utils_audio.py:check_audio_file:54)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_audio_file(AUDIO_FILE_PCM_MONO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 17:39:44,963 - micro - MainProcess - INFO     SESSION STARTED: SessionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c) (speech_to_text.py:<lambda>:241)\n",
      "2023-12-26 17:39:44,970 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,073 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,181 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,290 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,400 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,509 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,620 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,727 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,836 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:45,945 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,054 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,163 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,272 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,380 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,489 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,599 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,707 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,815 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:46,922 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,030 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,139 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,249 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,358 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,466 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,574 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,682 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,790 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:47,853 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=88e373882d34408395c84ebfb6383c85, text=\"the speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:47,897 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,016 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,127 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,236 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,270 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=909fb84e92db45b19cef90c3fe881453, text=\"the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:48,345 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,454 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,562 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,671 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,779 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,859 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4012acc0dc274a1586d0ab2ed2ad6f1d, text=\"the speech SDK exposes\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:48,888 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:48,996 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,104 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,212 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,243 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1f56be4aa3634c4f97a4398760c2c5ae, text=\"the speech SDK exposes many\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:49,320 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,429 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,538 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,554 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=e246b90c1e2b4d72b05a18b9297bdb88, text=\"the speech SDK exposes many features\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:49,645 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,754 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,852 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5f96b58d8d874d3e93a2664250be9ef2, text=\"the speech SDK exposes many features from the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:49,863 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:49,973 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,078 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,186 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,295 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,415 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f81caa425e4847ba995dc92530c112ca, text=\"the speech SDK exposes many features from the speech service\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:50,446 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,560 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,667 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,777 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,889 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:50,999 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,046 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a192d4da4ea14a93bb565c032e19d559, text=\"the speech SDK exposes many features from the speech service but not\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:51,108 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,216 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,324 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,358 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=91e8bccb5e2449088e4cc2728cdc49c5, text=\"the speech SDK exposes many features from the speech service but not all of them\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:51,433 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,541 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,649 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,758 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,867 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:51,976 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,087 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,197 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,306 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,415 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,524 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,631 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,758 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,867 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:52,974 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,083 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,133 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=d5e7006171dd480dab1d559d400c2715, text=\"the cap\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:53,192 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,301 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,410 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,428 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=9b4f07c73dee45ad9b1b932eb0e49e45, text=\"the capabilities\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:53,522 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,633 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,741 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,835 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a4e568573bfc4be3b40c267b2b2f1370, text=\"the capabilities of the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:53,849 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:53,958 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,036 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=3bef10545804420ea1d4646316978161, text=\"the capabilities of the speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:54,067 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,175 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,285 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,394 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,514 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,537 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=e5c18ecded5043c9926cc43b8fffa276, text=\"the capabilities of the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:54,626 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,737 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,845 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:54,848 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=6d6bd89395f64c19a44d48a570c42c58, text=\"the capabilities of the speech SDK are\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:54,954 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,062 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,171 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,280 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,342 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=180d2530eda54e2d9c70a0d0020d0ec6, text=\"the capabilities of the speech SDK are often\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:55,387 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,496 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,529 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5c353a4d53c74993a80d40b4d2a0b6bd, text=\"the capabilities of the speech SDK are often associated\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:55,604 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,713 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,822 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,932 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:55,934 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=11ae6ea7e694498ab8535b8c3def9c93, text=\"the capabilities of the speech SDK are often associated with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:56,043 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,152 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,230 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=b1b50ee761ba4d4a9d184fc8f2a0a40f, text=\"the capabilities of the speech SDK are often associated with scenarios\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:56,260 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,368 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,478 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,587 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,695 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,803 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:56,913 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,023 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,132 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,241 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,336 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=e6f1878eeeac493ebb046d9126fbf033, text=\"the capabilities of the speech SDK are often associated with scenarios the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:57,350 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,459 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,569 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,678 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,786 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:57,893 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,003 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,037 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5b6f67545d904f8d84e26482100cb4a6, text=\"the capabilities of the speech SDK are often associated with scenarios the speech S\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:58,111 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,217 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,324 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,340 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=87982db825314686babb1e1bef79df32, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:58,431 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,558 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,664 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,773 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,855 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=d51065564fa04069994abac07622a0b8, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:58,884 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:58,995 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,043 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5fe6c84d01394329917a584a7094f7ed, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:59,105 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,213 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,322 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,430 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,436 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=8d95f907ee074b94aabd0a3b9d42dc6e, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:39:59,540 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,649 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,758 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,865 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:39:59,973 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,083 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,145 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1049e3740e3f4d38bcc412fde2c3497b, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:00,189 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,305 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,408 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,440 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=2da1b4340abb4ef28551385d624e7345, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:00,517 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,628 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,735 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,843 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:00,845 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=976b6f1e926f40c2bc071685869a88ea, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:00,953 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,061 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,156 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4941fd01bb60483faee6891e9e0a605a, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and non\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:01,170 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,278 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,387 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,496 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,544 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=0d49234b7490440ea3a6110bbbbc6c47, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:01,604 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,712 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,821 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:01,839 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=0a022e91e8fc445f8b888f05a38a14c8, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:01,931 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,045 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,153 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,260 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,377 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,493 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,562 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f90eede3503c49dba6a8c59411b44122, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:02,603 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,708 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,819 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:02,927 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,008 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=fbaaf8e0c0ab4046927f0b39e51d76f9, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:03,037 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,146 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,255 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,258 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=7cdd3833507c4054877ffd1eef6129eb, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:03,364 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,472 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,581 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,692 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,802 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:03,911 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,035 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,146 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,253 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,361 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,455 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a3992adb22b84595850c58d17f6768c5, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:04,470 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,577 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,685 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,796 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:04,903 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,012 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,120 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,229 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,339 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,343 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=b3349d64ebbe4c9d8076efb01de6fa29, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:05,449 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,559 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,671 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,776 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,839 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=98f3285fc7fc4cb6a0bbf48548f62ab0, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:05,885 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:05,993 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,042 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=289f90146d1540309be5547f2aafdbd4, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:06,101 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,211 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,323 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,432 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,542 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,652 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,749 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=8c942c6b8f0c43a0a2db58971dced02c, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:06,762 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,869 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:06,976 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,085 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,149 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4fa26f791ef748278fb753b3cedb0a9c, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:07,194 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,314 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,426 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,444 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=85aedc8edefa41e297ea81648ecaba95, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:07,536 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,643 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,753 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,862 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,970 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:07,973 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=7418421e9b254631b6a3eaf7a021ac4a, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:08,079 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,188 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,297 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,406 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,515 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,624 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,736 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,845 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:08,953 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,063 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,171 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,319 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,350 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=6534766577e24a21a06fcef44a1507ed, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:09,420 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,529 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,547 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=040e67fe95ed4baa950344cd3b8aef95, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:09,637 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,747 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,858 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:09,936 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=fa24a5a468d54553a26dcf37bc6789b2, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:09,966 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,075 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,186 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,296 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,344 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f192013c82784c8890242c2a6de6c78c, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:10,405 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,514 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,623 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,655 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=0be5b716df9b494181a2f169075f5179, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:10,793 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:10,937 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,043 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,060 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=2b69dfeaf5744c52b0934de08154bc78, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:11,153 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,262 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,369 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,477 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,588 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,698 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,760 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=bbeea76c8710433595b1c4caab266fd5, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:11,807 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:11,917 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,024 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,132 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,241 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,350 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,459 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,577 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,693 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,802 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:12,910 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,018 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,127 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,144 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=c2176982f54747ed90ea4570762d5030, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:13,237 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,346 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,455 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,564 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,644 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=885bbb54afee4a4598aaac524c6e6517, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:13,674 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,782 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,893 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:13,943 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1068ae812eb3461e883d48e00969de43, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:14,004 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,118 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,223 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,241 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=ae1f3441a0fa4bb0831c070f820413bd, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest API\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:14,331 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,439 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,548 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,566 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1339366d4a744f708da78b71c933c842, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest API alternative\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:14,657 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,766 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,873 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:14,983 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,091 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,200 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,309 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,418 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,527 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,635 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,759 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,869 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:15,979 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,088 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,197 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,306 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,416 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,524 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,632 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,740 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,850 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:16,868 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=bff0721434364a8fabf06b030de59345, text=\"speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:16,960 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,069 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,177 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,284 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,468 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,577 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,685 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,794 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:17,827 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=2d557f05b88d48b5bb5fb3c98a2a5258, text=\"speech to text also known\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:17,904 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,013 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,122 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,125 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a042403d9f2c4345972e6e693da4bcf4, text=\"speech to text also known as\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:18,229 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,337 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,446 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,524 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5cbb23000f0e41d3bae436e5dbc9111f, text=\"speech to text also known as speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:18,582 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,695 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,805 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:18,821 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f2e6b425da0f49e78fc9d665126dd710, text=\"speech to text also known as speech recognition\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:18,915 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,028 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,131 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,239 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,347 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,454 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,563 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,672 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,781 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,889 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:19,999 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,031 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=7415134d04884d2e8f9373c5cd75d98b, text=\"speech to text also known as speech recognition transcri\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:20,108 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,217 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,249 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=7a4f588ad71f4b5da287879d546fd14d, text=\"speech to text also known as speech recognition transcribes\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:20,326 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,434 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,543 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,657 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4d4c86d3d2cf4ef9b13107bbdb993c69, text=\"speech to text also known as speech recognition transcribes aud\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:20,663 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,731 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1ed80d9d8421435da7bdddeeeecaad05, text=\"speech to text also known as speech recognition transcribes audio\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:20,775 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,884 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:20,994 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,027 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f4b091f83c1e451793651c9bcb7c46b9, text=\"speech to text also known as speech recognition transcribes audio streams\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:21,104 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,214 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,324 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,326 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=ac078efe09eb41e4ab578a983661936c, text=\"speech to text also known as speech recognition transcribes audio streams to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:21,433 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,540 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,647 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,759 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,866 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:21,975 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,083 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,191 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,323 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=bc6f6f0b3762494392b0c2557b4c30c7, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applic\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:22,346 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,456 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,565 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,675 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,784 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:22,818 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=b927cee0ebfd4e148dfe96d917b6db3f, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:22,893 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,002 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,110 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,220 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,328 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,436 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,545 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,639 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=84c19a2bcddf4f9cacc59757d643ddf1, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:23,652 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,734 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=750a212b61c0424e9f6a022adca5db97, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or dev\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:23,765 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,826 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=44c990813bb149948a3de5e783693b55, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:23,872 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:23,991 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,105 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,213 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,324 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,434 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,543 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,546 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=25346ed8c7b84cb9a365a7bde5eecc39, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices can consume\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:24,652 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,762 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,870 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:24,979 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,088 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,198 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,234 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=32063f17d6914370af096d629bb79879, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices can consume or display\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:25,308 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,420 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,529 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,639 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,764 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,885 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:25,994 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,101 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,211 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,321 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,431 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,539 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,648 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,758 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,866 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:26,974 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,082 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,145 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4908184dc398443cb158d402863fcbd8, text=\"use speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:27,190 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,309 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,423 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,426 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=878b194b408c45b28be727906522fd6d, text=\"use speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:27,532 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,640 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,736 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=4a9369f603424ca5ab525a870c294fd3, text=\"use speech to text with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:27,750 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,858 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:27,967 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,077 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,186 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,233 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=e32aa9a5a437438f9bfe2fbfa03e13d4, text=\"use speech to text with language\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:28,294 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,405 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,438 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=cdbabfc256d943cf8ff505e30615d665, text=\"use speech to text with language understanding\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:28,510 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,633 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,741 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,849 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:28,956 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,066 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,175 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,283 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,391 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,502 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,609 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,626 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a0ea356f2979412aafceb1c1d76c8527, text=\"use speech to text with language understanding louis\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:29,717 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,828 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:29,954 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,060 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,169 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,278 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,326 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=181078f9299449b98cff33f8b2e407ab, text=\"use speech to text with language understanding louis to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:30,386 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,496 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,604 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,637 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=3a2766528ec247a49296fa8f5b9faf86, text=\"use speech to text with language understanding louis to derive us\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:30,712 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,821 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,931 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:30,947 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=56313ccddcae4e87af740ec7e3b7a157, text=\"use speech to text with language understanding louis to derive user\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:31,040 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,150 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,237 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=7469de4c88394556903daa42a57c86e8, text=\"use speech to text with language understanding louis to derive user intents\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:31,277 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,337 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=db755836664f44b4959eccbdb933599e, text=\"use speech to text with language understanding louis to derive user intents from\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:31,382 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,490 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,600 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,710 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,743 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=77b35ba74cdc43d3849433fa6e90c6e9, text=\"use speech to text with language understanding louis to derive user intents from trans\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:31,820 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,927 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:31,929 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=8a9ebe25eccc4de3b9df13094c408cbc, text=\"use speech to text with language understanding louis to derive user intents from transcribed\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:32,035 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,144 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,253 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,331 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f2f139760b57441c80d48c1767c899da, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:32,363 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,470 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,578 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,686 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,766 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=6abc077127044849a6b950a2f2cdd3e6, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:32,811 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:32,920 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,028 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,137 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,187 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=813df330bda0491ab9ce524cdc9c7631, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:33,246 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,342 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=0efab12676cf4c008bb67ced987e2498, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:33,355 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,464 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,573 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,683 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,791 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:33,902 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,010 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,121 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,227 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,352 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,462 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,570 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,679 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,788 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:34,835 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=c5c459d4ed8a45288cf872a6ad71751f, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:34,897 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,005 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,115 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,223 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,258 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=1cce3a8d8b2b4d00b7287fc97f799d2c, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:35,332 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,441 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,446 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=5f82813e603f4191b17b1aea877e0708, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:35,551 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,660 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,769 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,881 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:35,973 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=9bb4dc9c9ba0493590957455d0d71c93, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:35,988 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,099 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,207 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,239 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=20b2de97b85e467ab035ee81f0f63754, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:36,316 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,427 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,536 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,645 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,664 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=070315c02ea34eb9b39dfb48e9770ca5, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:36,754 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,850 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=cc21434ae19c42ceaf0a0411cfcad009, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:36,864 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:36,972 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,080 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,192 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,300 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,377 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=419d639e08814560877c78d2d534a5d5, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:37,428 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,532 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,640 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,642 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=716411f927e74ed3acbc8a04a9d02c29, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:37,747 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,856 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:37,965 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,074 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,203 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,308 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,342 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=dee5fb7f87274dff97ecac769c8d03ba, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:38,416 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,523 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,645 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,742 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=2ab91410daf14fe59721669b844e0b2e, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:38,756 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,850 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=6a1d61562d7e46119139f88bc04ba26b, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:38,865 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:38,974 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,084 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,196 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,306 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,416 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,524 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,634 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,747 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:39,853 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,051 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,164 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,274 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,277 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=bbaed326dc534f48ba4becabdfd162d7, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:40,385 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,495 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,543 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=2714c111cfb64c0fbd923c70eeaa0827, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:40,602 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,713 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,821 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:40,931 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,040 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,176 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,291 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,406 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,512 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,620 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,652 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=f7c741b1a8464d9d880c19ea18629da3, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:41,729 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,836 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,944 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:41,946 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=a470af31c340496a885a7e191d895538, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:42,053 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,161 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,269 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,377 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,439 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=c4a2eb269c8d414c909e44f83519b008, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:42,486 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,593 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,688 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c, result=SpeechRecognitionResult(result_id=6ad2cab388a641478df885fd21527c7e, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech to text basics\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:237)\n",
      "2023-12-26 17:40:42,776 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:42,887 - micro - MainProcess - INFO     Mono data shape: (480,) (speech_to_text.py:speech_recognition_with_push_stream:280)\n",
      "2023-12-26 17:40:43,725 - micro - MainProcess - INFO     SESSION STOPPED SessionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c) (speech_to_text.py:<lambda>:244)\n",
      "2023-12-26 17:40:43,728 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=5734ba1770c04e2ca12c12f5dab4496c) (speech_to_text.py:stop_cb:232)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Speech SDK exposes many features from the Speech Service, but not all of them. The capabilities of the Speech SDK are often associated with scenarios. The Speech SDK is ideal for both real time and non real time scenarios using local devices, files, Azure BLOB storage and even input and output streams. When a scenario is not achievable with a Speech SDK, look for a REST API alternative. Speech to text, also known as speech recognition, transcribes audio streams to text that your applications, tools, or devices can consume or display. Use speech to text with language understanding. Louis to derive user intents from transcribed speech and act on voice commands. Use speech translation to translate speech input to a different language with a single call. For more information, see Speech to Text Basics.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber_client.speech_recognition_with_push_stream(audio_file=AUDIO_FILE_PCM_MONO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilly-speach-to-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
