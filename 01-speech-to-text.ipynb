{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have configured Azure AI services, set the appropriate configuration parameters, and set up a Conda environment to ensure reproducibility. You can find the setup instructions and how to create a Conda environment in the [REQUIREMENTS.md](REQUIREMENTS.md) file.\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "This notebook guides you through the following sections:\n",
    "\n",
    "1. [**Transcription Services**](transcription-services)\n",
    "\n",
    "    Azure AI's Speech SDK offers robust transcription services that convert spoken language into written text. This capability is useful in various scenarios, such as transcribing meetings, generating subtitles for videos, or enabling voice commands in applications. The following sections explore three different use cases:\n",
    "\n",
    "    1. [**Local Files**](#transcription-from-local-files): Learn how to transcribe audio from files stored on your machine. This is particularly useful when working with small to medium-sized files that can be easily accessed and processed locally.\n",
    "\n",
    "    2. [**Blob Storage**](#transcription-from-blob-storage): Discover how to transcribe audio from files stored in Azure Blob Storage. This approach is ideal for larger files that require the scalability and robustness of cloud storage.\n",
    "\n",
    "    3. [**Multi-language Auto Recognition**](#multi-language-auto-recognition-transcription): Explore the SDK's ability to automatically recognize and transcribe multiple languages within a single audio file. This feature is beneficial when dealing with multilingual content.\n",
    "\n",
    "    4. [**Enable Diarization (preview)**](#enable-diarization): Run an speech-to-text transcription with real-time diarization. Diarization is the process of distinguishing between different speakers participating in a conversation. The Speech service provides information about which speaker was speaking a particular part of the transcribed speech.\n",
    "    \n",
    "2. [**Real time speech to text (Streams)**](#streams): This section demonstrates how to convert speech to text from audio streams, using push streams for real-time processing.\n",
    "\n",
    "For more details, refer to the following resources:\n",
    "- [Quickstart: Azure Cognitive Services Speech SDK](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-speech-services\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory (change yours)\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-speech-services\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription Services\n",
    "\n",
    "### From Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SpeechTranscriber class from the speech_to_text module in the src.speech package\n",
    "from src.speech.speech_to_text import SpeechTranscriber\n",
    "\n",
    "# Create an instance of the SpeechTranscriber class\n",
    "transcriber_client = SpeechTranscriber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will transcribe speech from a local audio file using Azure AI's Speech SDK. The audio file we will be using is located at `gbbai-azure-ai-speech-services//utils//audio_data//english.wav`.\n",
    "\n",
    "The expected transcription (ground truth) is: \"Oh, he has been away from New York‚Äîhe has been all round the world. He doesn't know many people here, but he's very sociable, and he wants to know every one.\"\n",
    "\n",
    "We will use the `transcribe_speech_from_file_continuous` function, which performs continuous speech recognition with input from an audio file. This function takes several parameters, including the path to the local audio file, language settings, and auto-detection settings, and returns the transcribed text from the audio source.\n",
    "\n",
    "Here's how we call this function:\n",
    "\n",
    "```python\n",
    "transcriber_client.transcribe_speech_from_file_continuous(\n",
    "    file_path=AUDIO_FILE_PCM_STEREO\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_PCM_STEREO = \"utils//audio_data//english.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:01:43,452 - micro - MainProcess - INFO     Transcribing with diarization (speech_to_text.py:_transcribe:605)\n",
      "2024-01-09 23:01:43,456 - micro - MainProcess - INFO     SessionStarted event: SessionEventArgs(session_id=65104312d35940c283d29a83d0dec700) (speech_to_text.py:conversation_transcriber_session_started_cb:31)\n",
      "2024-01-09 23:01:44,000 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=5ea9c6cc850840bc9e3af4f6728a3de6, speaker_id=Unknown, text=oh he has been away from, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,091 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=260b537ab86e4de9badc3bb66ef9a3a4, speaker_id=Unknown, text=oh he has been away from new york, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,183 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=a57290d458e64a109838f560dfe36c0c, speaker_id=Unknown, text=oh he has been away from new york he has been, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,299 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=be20ed88d08b4f1a9eab93998dea9ada, speaker_id=Unknown, text=oh he has been away from new york he has been all round, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,384 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=ec79f813fd9c4c3b98b3d8e7cecd4ca0, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,492 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=c4cff6ab05b847f5b48c8e77414a93ed, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,600 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=faac8851a06e455bb6da1ab7daca88dc, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,693 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=2e484012272142258aded1e9d1242d35, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,787 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=ebbb954543e34d1cb0d1076280f73ce0, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable and, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:44,893 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=778def817cda418995cf89106bc783e2, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable and he, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:45,000 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=df23ded5f834468b9d853bdf85ac252c, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable and he wants, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:45,094 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=31ad7d5cd32d4695b5e0ea7d49d07530, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable and he wants to know, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:45,224 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=d5e92f4406554de3aa7cafd8f0e39714, speaker_id=Unknown, text=oh he has been away from new york he has been all round the world he doesn't know many people here but he's very sociable and he wants to know everyone, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:48,581 - micro - MainProcess - INFO     Updated final text:  Oh, he has been away from New York. He has been all round the world. He doesn't know many people here, but he's very sociable and he wants to know everyone. (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:01:49,264 - micro - MainProcess - INFO     Canceled event: ConversationTranscriptionCanceledEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=3377e356d2cb41e6aac4592d056b4c74, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:conversation_transcriber_recognition_canceled_cb:40)\n",
      "2024-01-09 23:01:49,268 - micro - MainProcess - INFO     CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=65104312d35940c283d29a83d0dec700, result=ConversationTranscriptionResult(result_id=3377e356d2cb41e6aac4592d056b4c74, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:01:49,269 - micro - MainProcess - INFO     SessionStopped event: SessionEventArgs(session_id=65104312d35940c283d29a83d0dec700) (speech_to_text.py:conversation_transcriber_session_stopped_cb:37)\n",
      "2024-01-09 23:01:49,273 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=65104312d35940c283d29a83d0dec700) (speech_to_text.py:stop_cb:641)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, he has been away from New York. He has been all round the world. He doesn't know many people here, but he's very sociable and he wants to know everyone.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber_client.transcribe_speech_from_file_continuous(\n",
    "    file_path=AUDIO_FILE_PCM_STEREO,\n",
    "    auto_detect_source_language=False,\n",
    "    diarization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Blob Storage\n",
    "\n",
    "The audio file we will be using is located at `https://testeastusdev001.blob.core.windows.net/speechapp/d6a35a5e-be01-40cd-b9ef-d61fcda699fa.pcm`. \n",
    "\n",
    "The expected transcription (ground truth) is: 'What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? Saturday, July 6th, 2024.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:01:50,207 - micro - MainProcess - INFO     Transcribing with diarization (speech_to_text.py:_transcribe:605)\n",
      "2024-01-09 23:01:50,223 - micro - MainProcess - INFO     SessionStarted event: SessionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f) (speech_to_text.py:conversation_transcriber_session_started_cb:31)\n",
      "2024-01-09 23:01:50,762 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=db504ade07ad48b68c21fb2eeb78a8a9, speaker_id=Unknown, text=what is the date, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:51,458 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=b38f7bd99d534551bd721f9782809cab, speaker_id=Unknown, text=what is the date may 15th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:51,557 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=76f8ff3a25c147a7b8d8f9d4e02506b0, speaker_id=Unknown, text=what is the date may 15th 1980, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:51,573 - micro - MainProcess - INFO     Updated final text:  What is the date? (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:01:52,278 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=b2b4da4204c64bc09e6eaa32ee23a654, speaker_id=Unknown, text=may 15th 1980, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:52,481 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=612be95f9d3044cbbebde03649c12b27, speaker_id=Unknown, text=may 15th 1980 thursday, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:52,882 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=ce0daa954a484c399ae3fb2adc48dcc2, speaker_id=Unknown, text=may 15th 1980 thursday may, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:53,079 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=354089d021a14e5583c202d451289681, speaker_id=Unknown, text=may 15th 1980 thursday may 15th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:53,484 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=0d91a7e2765b41078b5610fa3c2fb1b7, speaker_id=Unknown, text=may 15th 1980 thursday may 15th 19, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:53,593 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=8704eae9835948c2bebf212adea2daf9, speaker_id=Unknown, text=may 15th 1980 thursday may 15th 1900, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:53,795 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=afc6fe7ee2154414ad27fffd2833ac2c, speaker_id=Unknown, text=may 15th 1980 thursday may 15th 19180, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:54,029 - micro - MainProcess - INFO     Updated final text:  What is the date? May 15th, 1980. (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:01:54,709 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=b484f7acc8784463b224f5d122bd2a44, speaker_id=Unknown, text=thursday may 15th 19180, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:54,819 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=f6ba5d70418248e9b6ba7c025687af54, speaker_id=Unknown, text=thursday may 15th 19180 what is the date, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:55,245 - micro - MainProcess - INFO     Updated final text:  What is the date? May 15th, 1980. Thursday, May 15th, 19180. (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:01:55,632 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=c3f064a7bc31405c91cae1e529deb475, speaker_id=Unknown, text=what is the date, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:55,648 - micro - MainProcess - INFO     Updated final text:  What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:01:58,087 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=2ddf00259a78447b9b1fd4d04ddd176c, speaker_id=Unknown, text=saturday, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:58,278 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=2b57c4fd8dbf482c8b1e7b1eaa14e375, speaker_id=Unknown, text=saturday july, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:58,680 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=ce3f264bdbe746c5bd9f46132105317a, speaker_id=Unknown, text=saturday july 6th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:58,888 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=618bc5c1c48f4fc198ad8f41b8d8bcfa, speaker_id=Unknown, text=saturday july 6th 2:00, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:59,085 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=7a9bbcbe4fda49d2b4b4636c913c8e41, speaker_id=Unknown, text=saturday july 6th 2000, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:59,191 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=884d3b94a6bc41988d38085903f5fcd2, speaker_id=Unknown, text=saturday july 6th 2020, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:01:59,842 - micro - MainProcess - INFO     Updated final text:  What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? Saturday, July 6th, 2024. (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:02:00,751 - micro - MainProcess - INFO     Canceled event: ConversationTranscriptionCanceledEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=c084195b4ec5449286b5998ba458b4ed, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:conversation_transcriber_recognition_canceled_cb:40)\n",
      "2024-01-09 23:02:00,760 - micro - MainProcess - INFO     CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f, result=ConversationTranscriptionResult(result_id=c084195b4ec5449286b5998ba458b4ed, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:02:00,760 - micro - MainProcess - INFO     SessionStopped event: SessionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f) (speech_to_text.py:conversation_transcriber_session_stopped_cb:37)\n",
      "2024-01-09 23:02:00,767 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=d337d17f5d8848b18e1ca6b870affb2f) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:02:00,932 - micro - MainProcess - INFO     Deleted temporary file: C:\\Users\\pablosal\\AppData\\Local\\Temp\\tmpsenrz2pv (speech_to_text.py:_transcribe_from_blob:573)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the date? May 15th, 1980. Thursday, May 15th, 19180. What is the date? Saturday, July 6th, 2024.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_FROM_BLOB = \"https://testeastusdev001.blob.core.windows.net/speechapp/d6a35a5e-be01-40cd-b9ef-d61fcda699fa.pcm\"\n",
    "transcriber_client.transcribe_speech_from_file_continuous(blob_url=AUDIO_FROM_BLOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-language Auto Recognition Transcription\n",
    "\n",
    "In this section, we will transcribe speech from a local audio file in French using Azure AI's Speech SDK, which features automatic language detection. The audio file we will be using is located at `utils//audio_data//french.wav`. \n",
    "\n",
    "The expected transcription (ground truth) is: `En semaine, je me l√®ve √† 6h30, je prends une douche et un petit d√©jeuner et je pars au travail vers 7h15. Pour arriver √† mon entreprise √† 8 heures, il me faut environ 45 minutes en voiture, mais parfois j‚Äôarrive en retard √† cause des embouteillages.`\n",
    "\n",
    "We will use the `transcribe_speech_from_file_continuous` function, setting the `auto_detect_source_language` parameter to `True`. This allows the function to automatically detect the language spoken in the audio file. Currently, the supported languages are English (United States), Spanish (Spain), and French (France). However, you can add new languages using the `transcriber_client.add_supported_language` method or by passing the `auto_detect_source_language` parameter when calling the `transcribe_speech_from_file_continuous` function.\n",
    "\n",
    "For more information about the available languages, please visit the [Azure AI Services Language Support page](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:02:00,960 - micro - MainProcess - INFO     Transcribing with diarization (speech_to_text.py:_transcribe:605)\n",
      "2024-01-09 23:02:00,968 - micro - MainProcess - INFO     SessionStarted event: SessionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0) (speech_to_text.py:conversation_transcriber_session_started_cb:31)\n",
      "2024-01-09 23:02:01,919 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=af46564a1b7d4886b922f98c3fe7193d, speaker_id=Unknown, text=en sem, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,028 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=426be43b8e2f4295803a97257445417b, speaker_id=Unknown, text=en semaine je me, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,126 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=d7f0d1fcc29e44d4b80360092b5b7ea3, speaker_id=Unknown, text=en semaine je me l√®ve √†, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,218 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=9456bc04b81841c0ae4840d11c195a47, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,336 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=0c588e73b63e48248894918b167f19d2, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,431 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=5caa95f91b0e4c828ff1c572e27c4617, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,525 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=849cc047fecb45cbb139d2d09c8ea246, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un pet, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,619 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=86a4b0b5f65d47a9b7ef0498fd4217da, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,739 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=2a55e6d86a7847ed984bce5d85da3491, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,824 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=c1a162b3317848fd800df0c8ef8e61ef, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:02,929 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=49eb89c52ecc4e699d01213d2617ace6, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 7, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,025 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=878723f3aac14476987237a71f61a3da, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,223 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=269cac9ab0cc4090a938a4956b7a7d84, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,324 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=c4982c95cfa94e4880b0f1238e2548e9, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √†, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,426 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=55455a84926448bf976e13202a179683, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,531 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=08f95feb6ae44fb8937864143ed810c9, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,622 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=fabea266c4a143bdb3ebb9083ba31802, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 8, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:03,824 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=f5ea31de3be44aec84211cf0a552def8, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:04,132 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=6831c5cc183e4e85b86254e4d9afc0c9, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:04,330 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=1e790c2e38474b3aa6d8f5874a3d89ab, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:04,454 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=297f32e0fb3b495a96f586de919bd0ef, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:04,736 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=cd06c27f236145e6b923927d5fbcebb3, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 40, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:04,922 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=b6caa0d4a39849a3b3e506f03f7c7d88, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:05,033 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=8f41625b34ef49f19b3e6b9c9e9962b7, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:05,324 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=0e7b3c21f62b49828e5a14485dce7eb9, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:05,736 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=56a9de478ceb4fc5a42e70693fb5d52b, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:05,922 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=85f72cd246fb4cf3891d71da51a3578e, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'ar, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,121 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=659a46585fb04d1a9688b3259cb8b7a2, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,235 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=a4a1cbe7bf5541bdb8c637481514cd5e, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en retard, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,328 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=83ef451cf6df4d20a7d780adba3f8f36, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en retard √†, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,625 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=0adc77f0526d40b18b04396cac5bb146, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en retard √† cause, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,733 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=496f3b61cb4a446f84cd2c6685b62237, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en retard √† cause des, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:06,826 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=89781f5a62c747268b21116e407f8b86, speaker_id=Unknown, text=en semaine je me l√®ve √† 06h30 je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00 il me faut environ 45 min en voiture mais parfois j'arrive en retard √† cause des embouteillages, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:09,417 - micro - MainProcess - INFO     Updated final text:  En semaine, je me l√®ve √† 06h30, Je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00. Il me faut environ 45 Min en voiture, mais parfois j'arrive en retard √† cause des embouteillages. (speech_to_text.py:transcribed_cb:636)\n",
      "2024-01-09 23:02:09,493 - micro - MainProcess - INFO     Canceled event: ConversationTranscriptionCanceledEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=536e602e9eda4f98bd4fd51b55ff0b84, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:conversation_transcriber_recognition_canceled_cb:40)\n",
      "2024-01-09 23:02:09,507 - micro - MainProcess - INFO     CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0, result=ConversationTranscriptionResult(result_id=536e602e9eda4f98bd4fd51b55ff0b84, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:02:09,513 - micro - MainProcess - INFO     SessionStopped event: SessionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0) (speech_to_text.py:conversation_transcriber_session_stopped_cb:37)\n",
      "2024-01-09 23:02:09,519 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=7148d09395d642f9899b92f72a6d38c0) (speech_to_text.py:stop_cb:641)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"En semaine, je me l√®ve √† 06h30, Je prends une douche et un petit d√©jeuner et je pars au travail vers 07h15 pour arriver √† mon entreprise √† 08h00. Il me faut environ 45 Min en voiture, mais parfois j'arrive en retard √† cause des embouteillages.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_FILE_french = \"utils/audio_data/french.wav\"\n",
    "transcriber_client.transcribe_speech_from_file_continuous(\n",
    "    file_path=AUDIO_FILE_french, auto_detect_source_language=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Diarization (preview)\n",
    "\n",
    "The speaker information is included in the result in the `speaker ID` field. The `speaker ID` is a generic identifier assigned to each conversation participant by the service during the recognition process, as different speakers are identified from the provided audio content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:02:10,734 - micro - MainProcess - INFO     Transcribing with diarization (speech_to_text.py:_transcribe:605)\n",
      "2024-01-09 23:02:10,749 - micro - MainProcess - INFO     SessionStarted event: SessionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4) (speech_to_text.py:conversation_transcriber_session_started_cb:31)\n",
      "2024-01-09 23:02:11,591 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=5b719096b95e43c1a4eabeb38d106567, speaker_id=Unknown, text=what is the date, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:12,076 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=e50cd91aff7941e788cb7a0e90943806, speaker_id=Unknown, text=what is the date may 15th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:12,184 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=a9cec0ff5fe24ce6a4ec540dc5ae113f, speaker_id=Unknown, text=what is the date may 15th 1980, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:12,893 - micro - MainProcess - INFO     Updated final text: Speaker Guest-1: What is the date?\n",
      " (speech_to_text.py:transcribed_cb:630)\n",
      "2024-01-09 23:02:13,079 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=b517b920228348289d120e0ede4c84b4, speaker_id=Unknown, text=may 15th 1980 thursday, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:13,370 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=f7d6d0ac12424006aa64e86813f34d45, speaker_id=Unknown, text=may 15th 1980 thursday may, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:13,493 - micro - MainProcess - INFO     Updated final text: Speaker Guest-1: What is the date?\n",
      "Speaker Guest-1: May 15th, 1980.\n",
      " (speech_to_text.py:transcribed_cb:630)\n",
      "2024-01-09 23:02:13,635 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=432e5c26cb114861ae80beb1fbf0804b, speaker_id=Unknown, text=thursday may 15th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:14,051 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=ea6135f0b0c04d46ade00051e61cfe49, speaker_id=Unknown, text=thursday may 15th 19, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:14,244 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=ce2e880146154550b074a8e10be40191, speaker_id=Unknown, text=thursday may 15th 1900, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:14,342 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=3a23a214a4e24c3b86d012784d466ef3, speaker_id=Unknown, text=thursday may 15th 19180, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:15,149 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=8c11888b801540fbadfcc5491dbfb4e6, speaker_id=Unknown, text=thursday may 15th 19180 what is, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:15,342 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=5cf3aa6f563c494a9f38a620af59c2de, speaker_id=Unknown, text=thursday may 15th 19180 what is the date, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:15,517 - micro - MainProcess - INFO     Updated final text: Speaker Guest-1: What is the date?\n",
      "Speaker Guest-1: May 15th, 1980.\n",
      "Speaker Guest-2: Thursday, May 15th, 19180.\n",
      " (speech_to_text.py:transcribed_cb:630)\n",
      "2024-01-09 23:02:15,880 - micro - MainProcess - INFO     Updated final text: Speaker Guest-1: What is the date?\n",
      "Speaker Guest-1: May 15th, 1980.\n",
      "Speaker Guest-2: Thursday, May 15th, 19180.\n",
      "Speaker Guest-1: What is the date?\n",
      " (speech_to_text.py:transcribed_cb:630)\n",
      "2024-01-09 23:02:18,572 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=de3d9e92e77041bfb8b9a441944a005d, speaker_id=Unknown, text=saturday, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:18,777 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=5e2e0884606b4471bd888cf9309a5764, speaker_id=Unknown, text=saturday july, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:19,167 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=993f9bdb5ca44ae09f3584e7f06e5813, speaker_id=Unknown, text=saturday july 6, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:19,301 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=1a4aec6c33cb4b6ea41ef7e55e2b34c4, speaker_id=Unknown, text=saturday july 6th, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:19,470 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=7a00df3d034849bab0a6fbc6e42509f6, speaker_id=Unknown, text=saturday july 6th 2:00, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:19,698 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=711587668f56419187be8099be267cd4, speaker_id=Unknown, text=saturday july 6th 2000, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:19,870 - micro - MainProcess - INFO     Transcribing event: ConversationTranscriptionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=10d735f51fcd44b88e38a9df91f410d7, speaker_id=Unknown, text=saturday july 6th 2020, reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:conversation_transcriber_transcribing_started_cb:34)\n",
      "2024-01-09 23:02:20,517 - micro - MainProcess - INFO     Updated final text: Speaker Guest-1: What is the date?\n",
      "Speaker Guest-1: May 15th, 1980.\n",
      "Speaker Guest-2: Thursday, May 15th, 19180.\n",
      "Speaker Guest-1: What is the date?\n",
      "Speaker Guest-2: Saturday, July 6th, 2024.\n",
      " (speech_to_text.py:transcribed_cb:630)\n",
      "2024-01-09 23:02:21,447 - micro - MainProcess - INFO     Canceled event: ConversationTranscriptionCanceledEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=25ea4aeec81046a39453c6b8c3e6e123, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:conversation_transcriber_recognition_canceled_cb:40)\n",
      "2024-01-09 23:02:21,459 - micro - MainProcess - INFO     CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=b4815576a1294258aa7e78181b6621c4, result=ConversationTranscriptionResult(result_id=25ea4aeec81046a39453c6b8c3e6e123, speaker_id=, text=, reason=ResultReason.Canceled)) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:02:21,463 - micro - MainProcess - INFO     SessionStopped event: SessionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4) (speech_to_text.py:conversation_transcriber_session_stopped_cb:37)\n",
      "2024-01-09 23:02:21,463 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=b4815576a1294258aa7e78181b6621c4) (speech_to_text.py:stop_cb:641)\n",
      "2024-01-09 23:02:21,622 - micro - MainProcess - INFO     Deleted temporary file: C:\\Users\\pablosal\\AppData\\Local\\Temp\\tmpkxsfbhmj (speech_to_text.py:_transcribe_from_blob:573)\n"
     ]
    }
   ],
   "source": [
    "result = transcriber_client.transcribe_speech_from_file_continuous(\n",
    "    blob_url=AUDIO_FROM_BLOB, diarization=True, auto_detect_source_language=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Guest-1: What is the date?\n",
      "Speaker Guest-1: May 15th, 1980.\n",
      "Speaker Guest-2: Thursday, May 15th, 19180.\n",
      "Speaker Guest-1: What is the date?\n",
      "Speaker Guest-2: Saturday, July 6th, 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text from streams (preview):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.speech.utils_audio import check_audio_file, log_audio_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE_PCM_MONO = \"C://Users//pablosal//Desktop//gbbai-azure-ai-speech-services//utils//audio_data//aboutSpeechSdk.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:02:21,759 - micro - MainProcess - INFO     Number of Channels: 1 (utils_audio.py:log_audio_characteristics:75)\n",
      "2024-01-09 23:02:21,761 - micro - MainProcess - INFO     Sample Width: 2 (utils_audio.py:log_audio_characteristics:76)\n",
      "2024-01-09 23:02:21,764 - micro - MainProcess - INFO     Frame Rate: 16000 (utils_audio.py:log_audio_characteristics:77)\n",
      "2024-01-09 23:02:21,765 - micro - MainProcess - INFO     Number of Frames: 838880 (utils_audio.py:log_audio_characteristics:78)\n",
      "2024-01-09 23:02:21,767 - micro - MainProcess - INFO     Compression Type: NONE (utils_audio.py:log_audio_characteristics:79)\n",
      "2024-01-09 23:02:21,769 - micro - MainProcess - INFO     Compression Name: not compressed (utils_audio.py:log_audio_characteristics:80)\n",
      "2024-01-09 23:02:21,770 - micro - MainProcess - INFO     Bytes Per Second: 32000 (utils_audio.py:log_audio_characteristics:84)\n"
     ]
    }
   ],
   "source": [
    "log_audio_characteristics(AUDIO_FILE_PCM_MONO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:02:21,792 - micro - MainProcess - INFO     SESSION STARTED: SessionEventArgs(session_id=434de908c8084a1796b580789ba72e65) (speech_to_text.py:<lambda>:313)\n",
      "2024-01-09 23:02:21,802 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:21,915 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,028 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,143 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 23:02:22,252 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,376 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,490 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,619 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,748 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:22,976 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:23,292 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:23,515 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:23,774 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:24,454 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:24,579 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:24,692 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:24,868 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:24,983 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,092 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,307 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,430 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,580 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,763 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:25,875 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,132 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,288 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,395 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,458 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=1b57a4aeb7024995a614a177bb309872, text=\"the speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:26,504 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,611 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,722 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,756 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ee60dca8d38946aa9800b36248a72b0b, text=\"the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:26,831 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:26,939 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,048 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,167 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,277 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,392 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,460 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=5cb104853139487985957df6644fea53, text=\"the speech SDK exposes\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:27,507 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,620 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,733 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:27,776 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ba3ae7b62d67410bb5a10fbe185f4e6b, text=\"the speech SDK exposes many\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:27,862 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,022 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,135 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,263 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,263 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=26693850bb194351a3f40c1c73a7c8d7, text=\"the speech SDK exposes many features\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:28,374 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,535 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,554 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=7eec451af7c949c2a724dae89a831592, text=\"the speech SDK exposes many features from the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:28,647 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,760 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:28,888 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,015 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,150 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=c815b30b05314040a173a3b4dbda5b96, text=\"the speech SDK exposes many features from the speech service\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:29,157 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,270 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,383 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,494 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,605 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,748 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,765 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=5450222d8f2f45dbb4134e3d300eb555, text=\"the speech SDK exposes many features from the speech service but not\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:29,861 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:29,973 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,085 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,176 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=b9d34c1d205e429286a11d52469d6114, text=\"the speech SDK exposes many features from the speech service but not all of them\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:30,197 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,309 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,422 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,533 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,644 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,756 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,868 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:30,980 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,092 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,237 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,429 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,606 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,724 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,843 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:31,992 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,109 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,166 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d5981d56f4114fe594164cb9681a308a, text=\"the cap\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:32,296 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,418 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,558 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,577 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=4dd7b2068c8c4564bf9ad7c2aed7fd1c, text=\"the capabilities\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:32,692 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,814 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:32,942 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,068 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,084 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=08fdd9233fd84fa78ea8abb050b38212, text=\"the capabilities of the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:33,245 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,376 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d25d680ea274455e9e50b0a955389b85, text=\"the capabilities of the speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:33,393 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,516 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,643 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,792 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,873 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=31594903b18f4a8f9bb827e1be8714bd, text=\"the capabilities of the speech S\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:33,909 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:33,971 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=6d6fb96d89fd443a8bf8ef65d1bf4151, text=\"the capabilities of the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:34,041 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,184 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,289 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,376 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=c18cc4f301a64615a4baa06d3bb4596e, text=\"the capabilities of the speech SDK are\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:34,401 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,557 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,663 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,777 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=b15436f988454da1b2a1779e9a383a34, text=\"the capabilities of the speech SDK are often\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:34,787 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:34,902 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,008 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,075 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=a3c825c9f43f4424961b0507813f4884, text=\"the capabilities of the speech SDK are often associated\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:35,119 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,244 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,361 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,467 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=acfbd70cceb24edebb58eaec4d700a88, text=\"the capabilities of the speech SDK are often associated with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:35,483 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,595 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,873 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:35,974 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=3bc85c7d67d347b7b7a9fc01faf680bf, text=\"the capabilities of the speech SDK are often associated with scen\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:36,023 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,071 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=5ce27ca8a8f140d9a2c5437e279cd3c5, text=\"the capabilities of the speech SDK are often associated with scenarios\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:36,185 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,297 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,409 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,521 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,633 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,745 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,857 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:36,970 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,082 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,194 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,276 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=62f3abb09fe24cb890c542b22c42ba12, text=\"the capabilities of the speech SDK are often associated with scenarios the\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:37,309 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,418 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,546 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,659 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,769 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:37,866 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=cb0740f718a745c7a7c89d0eeb1e089a, text=\"the capabilities of the speech SDK are often associated with scenarios the speech S\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:37,892 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,061 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,209 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,353 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,379 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f03352a067714eed832528bf640a223a, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:38,474 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,587 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,700 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,826 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:38,877 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=77f88aa4696946e0b2cbdc48cd049e9b, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:39,159 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:39,470 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d7f384a2010f4140b536cbeaf853e912, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:39,629 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,005 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,133 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,392 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,480 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=b0bb225fb0f14dcd91e0111eb05a0ffd, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:40,496 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,592 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=6fb4c2952efc4f19b30e0856f65379a5, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:40,608 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,720 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,833 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:40,944 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,051 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,160 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,177 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d461820dcee74322b1361dcf65d78699, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:41,269 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,378 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,473 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=165f50a710284e41af1ce26bb6b4c6eb, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:41,486 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,593 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,701 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,810 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,919 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:41,982 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=16cb147dfff44d45b63293fd3b1a2b61, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:42,027 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,137 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,185 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=3d67b4178cf542f18d3dccefcd818bcf, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and non\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:42,245 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,356 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,464 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,570 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,587 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=4e402957831d409ba60b1969eb5fcbf0, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:42,678 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,683 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f07e1b59b54e41769529f88a48c7c8ea, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:42,787 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,895 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:42,975 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=8d4733a4c97b4cee9559e8c43e445c58, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:43,003 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,112 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,221 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,330 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,438 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,546 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,580 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=3e74b17cb4d641c8a6ab77e7da0026c7, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:43,655 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,763 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,871 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,978 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:43,982 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ad23354d75854d95ae8802084f13ccd2, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:44,087 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,193 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,302 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,380 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=bc2e7c7a18cb4ad8acc5835753dd0a40, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:44,410 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,519 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,627 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,736 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,844 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:44,951 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,060 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,170 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,293 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,409 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,488 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ed29e507823e4483ab31532f0b7b6319, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:45,517 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,624 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,733 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,841 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:45,951 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,059 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,168 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,275 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,384 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,388 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=811b2cf3a395426db3ccd613d662ce30, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files a\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:46,478 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=810f326eb6b04ed981f94366aff155f4, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:46,495 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,602 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,711 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,819 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:46,884 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f44b4d29a635468abee98b399ae84f64, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:46,928 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,037 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,086 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=cb1508ccd7e04817949cc44cbd3f9abc, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:47,145 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,254 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,363 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,471 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,580 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,690 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,798 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:47,878 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=10547158481a43d9ab893bb04e9bf935, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:47,908 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,016 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,123 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,236 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,240 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=1e4f21c3ea7746bda2add5abb4faace8, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:48,341 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,453 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,486 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=1dc01928142a40a1933c71ad6f29c54a, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:48,563 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,671 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,781 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,889 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:48,984 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=48b11c0512804dd1bdee700ae0bfcaf1, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:48,995 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,103 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,213 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,321 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,444 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,556 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,665 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,772 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,881 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:49,989 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,097 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,207 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,315 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,395 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=774b6f1a36d4496283f5b2c43ecb44c9, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:50,424 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,534 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,582 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ed905a375e2a4cb88128dca5a4d06122, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:50,643 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,753 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,861 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,970 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:50,989 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=b79c0b31952448de8b09e86e17219872, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:51,080 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,189 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,297 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,392 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=2c00158034a84180a5093267f0b3d1ac, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:51,407 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,516 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,625 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,688 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ec040f3f85b5452a97d2815cbf486fac, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:51,732 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,841 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,951 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:51,985 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=180c24ba701a4f3ca68289a780944dcd, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:52,059 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,170 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,279 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,387 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,496 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,604 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,695 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=a57c608a0032429f8a30bbbd1818bd28, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:52,712 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,819 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:52,927 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,036 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,145 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,253 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,361 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,470 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,578 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,685 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,794 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:53,902 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,011 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,090 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=079838a104904b7c9d0dcee10820e357, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:54,119 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,229 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,337 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,445 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,495 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ae4ff2129d5846c28b237d9e2eeb13b0, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:54,553 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,663 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,771 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:54,790 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=5eb6f1ec1b24423faa8d9b7189f46c1f, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:54,894 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,000 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,114 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,188 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=02f28c8942ff49379bd2114c5bb2c997, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest API\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:55,219 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,329 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,436 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,498 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=03189f9793f844d7bc92ffec9f37e802, text=\"the capabilities of the speech SDK are often associated with scenarios the speech SDK is ideal for both real time and nonreal time scenarios using local devices files azure BLOB storage and even input and output streams when a scenario is not achievable with a speech SDK look for a rest API alternative\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:55,543 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,660 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,762 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,871 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:55,980 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,085 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,194 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,301 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,411 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,518 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,626 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,734 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,845 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:56,952 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,061 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,179 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,310 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,418 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,527 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,633 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,741 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,806 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=7bad0e18e8c641be85221f6428b0e0c3, text=\"speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:57,849 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:57,991 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,099 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,209 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,318 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,426 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,536 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,645 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,753 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,757 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=52fe6574d3784f7da5debf22c4c79638, text=\"speech to text also known\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:58,862 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:58,977 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,052 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=90c00f559f0e49e1ba5ffd2377445036, text=\"speech to text also known as\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:59,081 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,190 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,297 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,407 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,454 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=549c9bcd0ae2403786fd23df7015ac0b, text=\"speech to text also known as speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:59,572 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,685 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,750 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=c91fb5854f854eddbe8f657b1b368331, text=\"speech to text also known as speech recognition\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:02:59,832 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:02:59,934 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,042 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,150 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,258 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,371 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,474 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,583 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,691 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,794 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,904 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:00,954 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=4ef6bd3f71504c0bb213274b59ae1910, text=\"speech to text also known as speech recognition transcri\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:01,011 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,119 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,152 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=a8d9707d1bd84f618e397eb8cbc8349f, text=\"speech to text also known as speech recognition transcribes\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:01,227 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,336 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,446 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,554 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,561 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=fc8735e2c823437ca1aac4b300beaab3, text=\"speech to text also known as speech recognition transcribes audio\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:01,682 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,787 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,895 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:01,958 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=960d870d846c4cdc83b0571956227b1c, text=\"speech to text also known as speech recognition transcribes audio streams\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:02,002 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,107 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,215 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,275 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=e7c3e8d273fc4185b4727abd7acd1cba, text=\"speech to text also known as speech recognition transcribes audio streams to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:02,324 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,432 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,540 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,654 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,764 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,870 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:02,979 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,131 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,241 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,277 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=6c8db673c09948b6af570147440eb39a, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applic\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:03,349 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,457 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,566 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,674 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,777 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=587c090ec55c407e90e82b3433bef6e9, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:03,791 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:03,906 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,014 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,124 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,233 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,341 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,457 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,470 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=4448f5d52d7044d98a0e15c1f2bd7c79, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:04,578 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,686 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,750 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ae56859f16bb4431af873da470654e64, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:04,794 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:04,903 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,024 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,133 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,247 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,354 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,460 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,467 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=eee26a594e3d44c69f678b462737ea49, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices can consume\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:05,568 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,676 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,791 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:05,909 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,018 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,126 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,159 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=21880a3ab16e45509720dcd171208610, text=\"speech to text also known as speech recognition transcribes audio streams to text that your applications tools or devices can consume or display\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:06,234 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,339 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,449 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,558 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,666 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,775 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,885 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:06,993 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,138 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,243 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,350 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,459 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,567 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,676 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,797 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:07,909 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,018 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,111 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d22d8394f74443748a5248a7ef3f9d5d, text=\"use speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:08,125 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,235 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,349 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,391 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=1c862dbab45742a0a0648f14075721d2, text=\"use speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:08,467 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,577 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,699 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,704 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=63eea15542f84c8b9c2f34405ecbfa13, text=\"use speech to text with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:08,806 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:08,915 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,023 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,130 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,193 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=4a594cd18ef14e02885050ecc097437d, text=\"use speech to text with language\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:09,238 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,345 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,394 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=18ab3d71e6044b39b60c9d6e5a04a326, text=\"use speech to text with language understanding\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:09,454 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,563 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,673 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,781 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,896 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:09,998 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,106 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,215 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,322 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,431 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,541 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,606 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=e62ecf7e734c45e9aa1dfe6218515739, text=\"use speech to text with language understanding louis\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:10,649 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,757 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,865 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:10,973 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,082 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,191 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,300 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,409 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,418 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ff1e07efa33647a88fe079366fe5be38, text=\"use speech to text with language understanding louis to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:11,518 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,598 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=5cc34f0d0e94419ab8fdbd1ba89d1e04, text=\"use speech to text with language understanding louis to derive us\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:11,627 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,738 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,847 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:11,894 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d03ebded2bf24f97b0e269e195472bf9, text=\"use speech to text with language understanding louis to derive user\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:11,954 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,067 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,173 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,207 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d7c95af94a134564abf9f2fa2c54c9b1, text=\"use speech to text with language understanding louis to derive user intents from\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:12,280 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,388 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,498 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,607 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,703 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=3263127399c94a26b5a76d96d38a9cf8, text=\"use speech to text with language understanding louis to derive user intents from trans\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:12,715 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,824 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:12,907 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=38f074ec54f94c48a6a013a0b515adf8, text=\"use speech to text with language understanding louis to derive user intents from transcribed\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:12,937 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,053 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,163 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,271 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,303 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=aaaae04a4b47423f9d69043faff1c726, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:13,379 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,486 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,595 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,598 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=b81a21f5c8814d86b211d58ad03eb6e1, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:13,705 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,813 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:13,922 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,031 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,110 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=e261333ac4654075954e572b393cb7a4, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:14,140 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,247 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,310 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=019a6f84318b4001847b107adb2e7113, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:14,355 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,502 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,617 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,726 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,834 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:14,942 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,052 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,162 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,270 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,384 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,487 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,596 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,706 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,712 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=2f45b51d9d5448cb8303d122efb41fa2, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:15,811 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:15,922 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,031 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,139 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,218 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d8168c8d1b44474584d1d557e2844793, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:16,297 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,403 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,406 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=603be6be4b1043ba88ea44c243c6f1fe, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:16,512 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,621 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,731 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,846 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:16,904 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=8d52b70ebb5d42e7a350fb11685f950b, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:16,948 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,056 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,166 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,214 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=ecaf2e23b6d14362b555e47f979bccd9, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:17,275 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,384 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,491 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,601 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=06ecf17129cd40c9a6356a9eb2e17c96, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:17,606 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,710 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,819 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:17,913 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=65f19901e9284ddea8b02ee553540366, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:17,928 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,037 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,174 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,284 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,300 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=97cfec4cddbd4b07b5ecbc64713b542c, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:18,391 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,500 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,609 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,615 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=bf0cac0298d74218ae9cc17ed696865a, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a differe\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:18,716 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=48a2205859d8440a8b0c7c86daac5936, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:18,741 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,860 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:18,968 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,077 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,185 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,293 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,315 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=d722fc57ef4243f5bb52d6057b613a3b, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:19,404 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,515 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,621 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,728 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,807 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=0eb1e8e91b9e4ca68617c3d72b8a152a, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:19,838 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:19,945 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,055 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,164 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,277 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,383 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,489 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,606 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,716 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,833 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:20,950 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,056 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,165 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,213 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=72ff7c813fe644f4b666f7afc228bbae, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:21,273 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,382 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,416 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f311fc86628d4ff59c155d9a502e0c85, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:21,491 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,600 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,710 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,818 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:21,927 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,039 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,147 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,256 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,365 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,472 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,513 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f2fe8ffe2279436f8d52aef0f30d8958, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:22,588 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,695 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,803 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:22,807 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=f610bb9a1e7647949373b9fb608bbeb0, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:22,912 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,023 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,136 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,243 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,374 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,379 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=6025ba2678be456397d938ffb92278e1, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech to text\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:23,491 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,510 - micro - MainProcess - INFO     RECOGNIZING: SpeechRecognitionEventArgs(session_id=434de908c8084a1796b580789ba72e65, result=SpeechRecognitionResult(result_id=3126b00b41c542ba8a8b0baddb46165f, text=\"use speech to text with language understanding louis to derive user intents from transcribed speech and act on voice commands use speech translation to translate speech input to a different language with a single call for more information see speech to text basics\", reason=ResultReason.RecognizingSpeech)) (speech_to_text.py:<lambda>:309)\n",
      "2024-01-09 23:03:23,600 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,709 - micro - MainProcess - INFO     Mono data shape: (1600,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:23,819 - micro - MainProcess - INFO     Mono data shape: (480,) (speech_to_text.py:speech_recognition_with_push_stream:352)\n",
      "2024-01-09 23:03:24,593 - micro - MainProcess - INFO     SESSION STOPPED SessionEventArgs(session_id=434de908c8084a1796b580789ba72e65) (speech_to_text.py:<lambda>:316)\n",
      "2024-01-09 23:03:24,596 - micro - MainProcess - INFO     CLOSING on SessionEventArgs(session_id=434de908c8084a1796b580789ba72e65) (speech_to_text.py:stop_cb:304)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Speech SDK exposes many features from the Speech Service, but not all of them. The capabilities of the Speech SDK are often associated with scenarios. The Speech SDK is ideal for both real time and non real time scenarios using local devices, files, Azure BLOB storage and even input and output streams. When a scenario is not achievable with a Speech SDK, look for a REST API alternative. Speech to text, also known as speech recognition, transcribes audio streams to text that your applications, tools, or devices can consume or display. Use speech to text with language understanding. Louis to derive user intents from transcribed speech and act on voice commands. Use speech translation to translate speech input to a different language with a single call. For more information, see Speech to Text Basics.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber_client.speech_recognition_with_push_stream(audio_file=AUDIO_FILE_PCM_MONO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lilly-speach-to-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
